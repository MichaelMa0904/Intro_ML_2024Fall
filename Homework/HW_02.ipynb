{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - NRI Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __1. Import the NRI data. Ensure that the [FIPS code]\n",
    "# (https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code) \n",
    "# variable ('STCOFIPS') is correctly identified as a string / character variable. \n",
    "# Otherwise, the leading zeros will be removed.__\n",
    "\n",
    "# Change the columns type while import the data to make sure the leading 0 are correctly included\n",
    "NRI = pd.read_csv('NRI_Table_Counties.csv', dtype={'STCOFIPS': str})\n",
    "NRI['STCOFIPS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __2. Subset the NRI data to include only the 5-digit state/county \n",
    "# FIPS code and all colums ending with '\\_AFREQ' and '\\_RISKR'. \n",
    "# Each of these columns represents a different hazard type.\n",
    "NRI_Sub = NRI.filter(regex='(_AFREQ|_RISKR)$')\n",
    "NRI_Sub = NRI_Sub.join(NRI[['STCOFIPS']]) ## Also include the 5-digit state/county FIPS Code \n",
    "\n",
    "# Make sure the unique value is correct\n",
    "NRI_Sub['STCOFIPS'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __3. Create a table / dataframe that, for each hazard type, \n",
    "# shows the number of missing values in the '\\_AFREQ' and '\\_RISKR' columns.\n",
    "NRI_Missing = NRI_Sub.melt(var_name='Column', value_name='Value')\n",
    "NRI_Missing = NRI_Missing.groupby('Column')['Value'].apply(lambda x: x.isnull().sum()).reset_index()\n",
    "NRI_Missing['Type'] = NRI_Missing['Column'].str[-5:]\n",
    "NRI_Missing['Hazard_Type'] = NRI_Missing['Column'].str[:4] \n",
    "NRI_Missing = NRI_Missing[NRI_Missing['Column'] != 'STCOFIPS']\n",
    "NRI_Missing = NRI_Missing.drop(columns={'Column'})\n",
    "\n",
    "NRI_Missing = pd.pivot_table(NRI_Missing, values=['Value'],\n",
    "                             index=['Hazard_Type'],\n",
    "                             columns=['Type'],\n",
    "                             aggfunc=\"sum\",\n",
    "                             fill_value=0).reset_index()\n",
    "\n",
    "NRI_Missing.columns = NRI_Missing.columns.droplevel(0)\n",
    "new_column_names = ['Hazard_Type', 'Missing_AFREQ', 'Missing_RISKR']\n",
    "NRI_Missing.columns = new_column_names\n",
    "print(NRI_Missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __4. Show the cross-tabulation of the 'AVLN_AFREQ' and 'AVLN_RISKR' columns \n",
    "# (including missing values). What do you observe?_\n",
    "\n",
    "cross_tab = pd.crosstab(NRI_Sub['AVLN_AFREQ'], NRI_Sub['AVLN_RISKR'], dropna=False)\n",
    "NRI_Sub['AVLN_RISKR'].unique()\n",
    "cross_tab\n",
    "## Findings: As the AVLN_AFREQ frequency increases, the relatively risk also increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __5. Assuming that a risk that is \"not applicable\" to a county has an annualized frequency of 0, \n",
    "# impute the relevant missing values in the '\\_AFREQ' columns with 0.\n",
    "AFREQ_col = NRI_Sub.filter(regex='_AFREQ$')\n",
    "NRI_Sub[AFREQ_col.columns] = AFREQ_col.fillna(0)\n",
    "NRI_Sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - SVI Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __1. Import the SVI data. Ensure that the FIPS code is correctly identified as a string / character variable.\n",
    "#  Otherwise, the leading zeros will be removed.__\n",
    "\n",
    "SVI = pd.read_csv('SVI_2022_US_county.csv', dtype={'FIPS':str})\n",
    "\n",
    "# __1. Subset the SVI data to include only the following columns:__\n",
    "# `ST, STATE, ST_ABBR, STCNTY, COUNTY, FIPS, LOCATION, AREA_SQMI, E_TOTPOP, EP_POV150, EP_UNEMP, EP_HBURD, EP_NOHSDP, \n",
    "# EP_UNINSUR, EP_AGE65, EP_AGE17, EP_DISABL, EP_SNGPNT, EP_LIMENG, EP_MINRTY, EP_MUNIT, EP_MOBILE, EP_CROWD, EP_NOVEH, \n",
    "# EP_GROUPQ, EP_NOINT, EP_AFAM, EP_HISP, EP_ASIAN, EP_AIAN, EP_NHPI, EP_TWOMORE, EP_OTHERRACE`\n",
    "\n",
    "columns_to_use = [\n",
    "    'ST', 'STATE', 'ST_ABBR', 'STCNTY', 'COUNTY', 'FIPS', 'LOCATION', 'AREA_SQMI', 'E_TOTPOP', 'EP_POV150', \n",
    "    'EP_UNEMP', 'EP_HBURD', 'EP_NOHSDP', 'EP_UNINSUR', 'EP_AGE65', 'EP_AGE17', 'EP_DISABL', 'EP_SNGPNT', \n",
    "    'EP_LIMENG', 'EP_MINRTY', 'EP_MUNIT', 'EP_MOBILE', 'EP_CROWD', 'EP_NOVEH', 'EP_GROUPQ', 'EP_NOINT', \n",
    "    'EP_AFAM', 'EP_HISP', 'EP_ASIAN', 'EP_AIAN', 'EP_NHPI', 'EP_TWOMORE', 'EP_OTHERRACE'\n",
    "]\n",
    "SVI_Sub = SVI[columns_to_use]\n",
    "print(SVI_Sub.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __2. Create a table / dataframe that shows the number of missing values in each column.\n",
    "# (Hint: if you wrote a function for Task 1, you can reuse it here.)\n",
    "\n",
    "# Function to calculate the number of missing values in each column\n",
    "def missing_val(table):\n",
    "    missing = table.isnull().sum()\n",
    "    return pd.DataFrame(missing, columns=['Missing_Val'])\n",
    "\n",
    "# Applying the function to the loaded DataFrame\n",
    "SVI_Missing = missing_val(SVI_Sub)\n",
    "\n",
    "# Display the resulting DataFrame (Apparently there are no missing values)\n",
    "SVI_Missing\n",
    "\n",
    "# Check the original subset table to see if the function was written correctly\n",
    "SVI_Sub.columns[SVI_Sub.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Data Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __1. Identify any FIPS codes that are present in the NRI data but not in the SVI data and vice versa. /\n",
    "# Describe any discrepancies and possible causes? What to these discrepancies, if any, \n",
    "# mean for interpreting results based on the merged dataset moving forward?\n",
    "\n",
    "# First get the FIPS code from both dataset\n",
    "NRI_FIPS = NRI['STCOFIPS']\n",
    "SVI_FIPS = SVI['FIPS']\n",
    "\n",
    "# FIPS codes that are in NRI but not in SVI\n",
    "# FIPS codes that are in SVI but not in NRI\n",
    "FIPS_NRI_NotSVI = NRI_FIPS[~NRI_FIPS.isin(SVI_FIPS)]\n",
    "FIPS_SVI_NotNRI = SVI_FIPS[~SVI_FIPS.isin(NRI_FIPS)]\n",
    "\n",
    "# See what are the missing gepgraphy in the SVI\n",
    "FIPS_NRI_NotSVI_check = FIPS_NRI_NotSVI.to_list()\n",
    "NRI[NRI['STCOFIPS'].isin(FIPS_NRI_NotSVI_check)]['STATE'].unique()\n",
    "\n",
    "#############################\n",
    "## Answer: Looks like one state Connecticut and other special terrotories like American Samoa, Guam ... are not included in the SVI dataset. From the website of NRI\n",
    "## I can see the the NRI dataset includes American Samoa, Commonwealth of the Northern Mariana Islands, Guam, Puerto Rico, and the U.S. Virgin Islands.The missing county in connecticut includes\n",
    "## all the normal county geo names we see in other dataset. However, the connecticut geo in the SVI dataset are specified as planning region (https://storymaps.arcgis.com/stories/23bc7986213547a79cb8a5dafa84d68d)\n",
    "## It looks like the plannign regions in CT are being treated by tehe offical County equivalents by the Census Bureau due to the file changes by the CT state. \n",
    "\n",
    "# See what are the missing gepgraphy in the NRI\n",
    "FIPS_SVI_NotNRI_check = FIPS_SVI_NotNRI.to_list()\n",
    "SVI[SVI['FIPS'].isin(FIPS_SVI_NotNRI_check)]\n",
    "\n",
    "#############################\n",
    "## Answer: looks like NRI does not have special County geo like planning region that shows in the table in the connecticut. As stated above, SVI uses planning regiong for the County equivalent\n",
    "## as apposed to the NRI uses of traditional county definition.\n",
    "\n",
    "#############################\n",
    "## Answer: These results are different might be due to the fact that data collected by the SVI better reflect the census bureau geo definition and the year of data collected. Howeverm for the state of connecticut,\n",
    "## we might need to do some geoanalysis to map the traditional county to the planning region in order to generalize the analysis. Otherwise, the CT analysis will create discrepency since the planning region\n",
    "## seems better reflect the devlopment and demographics of the population in the state, but not the traditional county definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __2. Merge the NRI and SVI data on the FIPS code. Use an outer join to keep all counties in the final dataset.\n",
    "Merge_SVI_NRI = pd.merge(NRI, SVI, left_on='STCOFIPS', right_on='FIPS', how= 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __3. Create a table / dataframe that shows the number of missing values in each column of the merged dataset.\n",
    "# Applying the previous created function\n",
    "Merge_SVI_NRI_missing = missing_val(Merge_SVI_NRI)\n",
    "Merge_SVI_NRI_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __1. For each numerical variable in the merged dataset, plot a histogram showing the distribution of values.\n",
    "# (Hint: write a function to make the histogram for a single variable, then use a loop or apply function to make the histograms for all numerical variables.)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Merge_SVI_NRI\n",
    "\n",
    "def his_SVI_NRI(df, columns):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(df[columns].dropna(), bins=20, edgecolor='black')\n",
    "    plt.title(f'Stats of the {columns}')\n",
    "    plt.xlabel(columns)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "numerical_col = Merge_SVI_NRI.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "for col in numerical_col:\n",
    "    his_SVI_NRI(Merge_SVI_NRI, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbconvert import HTMLExporter\n",
    "import nbformat\n",
    "\n",
    "# Load the uploaded Jupyter notebook file\n",
    "notebook_filename = \"C:/users/hma/code/Michael_Homework/Intro_ML_2024Fall/hw_progress/HW_02.ipynb\"\n",
    "\n",
    "# Read the notebook content\n",
    "with open(notebook_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook_content = nbformat.read(f, as_version=4)\n",
    "\n",
    "# # Create an HTML exporter\n",
    "html_exporter = HTMLExporter()\n",
    "html_exporter.exclude_input = False  # Include code inputs in the exported HTML\n",
    "\n",
    "# Export the notebook to HTML format\n",
    "(body, resources) = html_exporter.from_notebook_node(notebook_content)\n",
    "\n",
    "# Define the output HTML filename\n",
    "output_html_filename = \"HW_02.html\"\n",
    "\n",
    "# Save the HTML output to a file\n",
    "with open(output_html_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
